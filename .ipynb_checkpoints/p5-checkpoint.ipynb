{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle Detection + Advanced Lane Finding\n",
    "\n",
    "The goals / steps of this project are the following:\n",
    "\n",
    "* Perform a Histogram of Oriented Gradients (HOG) feature extraction on a labeled training set of images and train a classifier Linear SVM classifier.\n",
    "* Apply a color transform and append binned color features, as well as histograms of color, to HOG feature vector.\n",
    "* Normalize features and randomize a selection for training and testing.\n",
    "* Implement a sliding-window technique and use trained classifier to search for vehicles in images.\n",
    "* Run pipeline on a video stream (start with the test_video.mp4 and later implement on full project_video.mp4) and create a heat map of recurring detections frame by frame to reject outliers and follow detected vehicles.\n",
    "* Estimate a bounding box for vehicles detected.\n",
    "* Add Advanced Lane Finding pipeline.\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np                 # NumPy\n",
    "import cv2                         # openCV\n",
    "import glob                        # Filename pattern matching\n",
    "import matplotlib.pyplot as plt    # 2D plotting\n",
    "import matplotlib.image as mpimg\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "# Visualizations will be shown in the notebook\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the camera calibration points using chessboard images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def calculate_mtx_dist(images, nx = 9, ny = 6, verbose = False):\n",
    "\n",
    "    # prepare object points, like (0,0,0), (1,0,0), (2,0,0) ....,(6,5,0)\n",
    "    objp = np.zeros((ny*nx,3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:nx, 0:ny].T.reshape(-1,2)\n",
    "\n",
    "    # Arrays to store object points and image points from all the images.\n",
    "    objpoints = [] # 3d points in real world space\n",
    "    imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "    # Step through the list and search for chessboard corners\n",
    "\n",
    "    imgs = images\n",
    "\n",
    "    if verbose:\n",
    "      imgs = tqdm(images)\n",
    "\n",
    "    for idx, fname in enumerate(imgs):\n",
    "        img = cv2.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Find the chessboard corners\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "\n",
    "        # print('ret =', ret)\n",
    "\n",
    "        # If found, add object points, image points\n",
    "        if ret == True:\n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "\n",
    "            # Draw and display the corners\n",
    "            if verbose:\n",
    "              cv2.drawChessboardCorners(img, (nx,ny), corners, ret)\n",
    "              write_name = 'output_images/corners_found/corners_found'+str(idx)+'.jpg'\n",
    "              cv2.imwrite(write_name, img)\n",
    "            # cv2.imshow('img', img)\n",
    "            # cv2.waitKey(500)\n",
    "\n",
    "    # Test undistortion on an image\n",
    "    # img = cv2.imread('camera_cal/calibration1.jpg')\n",
    "    img = cv2.imread(images[0])\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "    # Do camera calibration given object points and image points\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size, None, None)\n",
    "\n",
    "    return mtx, dist\n",
    "\n",
    "nx = 9\n",
    "ny = 6\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "mtx_dist_save_file = 'dist_pickle.p'\n",
    "\n",
    "# Calculate calibration matrix\n",
    "mtx, dist = calculate_mtx_dist(images, nx=9, ny=6, verbose=True)\n",
    "\n",
    "\n",
    "# Save Distortion matrix and coefficient\n",
    "with open(mtx_dist_save_file, 'wb') as f:\n",
    "    saved_obj = {\"mtx\": mtx, \"dist\" : dist}\n",
    "    pickle.dump(saved_obj, f)\n",
    "\n",
    "\n",
    "# Load Saved Camera Matrix and Distortion Coefficients\n",
    "dist_pickle = pickle.load(open(mtx_dist_save_file, \"rb\" ))\n",
    "mtx = dist_pickle[\"mtx\"]\n",
    "dist = dist_pickle[\"dist\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Distortion correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def undistort(img):\n",
    "    result = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For universal plotting of results\n",
    "def plot_row2(img1, img2, label_1, label_2, graysc=True):\n",
    "    # Plot the result (1 row with 2 images)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 6))\n",
    "    f.tight_layout()\n",
    "    if graysc:\n",
    "        ax1.imshow(img1, cmap='gray')\n",
    "    else:\n",
    "        ax1.imshow(img1)\n",
    "    ax1.set_title(label_1, fontsize=16)\n",
    "    ax2.imshow(img2, cmap='gray')\n",
    "    ax2.set_title(label_2, fontsize=16)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective transform\n",
    "\n",
    "Pick four points in a trapezoidal shape (similar to region masking) that would represent a rectangle when looking down on the road from above.\n",
    "\n",
    "The easiest way to do this is to investigate an image where the lane lines are straight, and find four points lying along the lines that, after perspective transform, make the lines look straight and vertical from a bird's eye view perspective."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Applies an image mask\n",
    "# Only keeps the region of the image defined by the polygon formed from `vertices`.\n",
    "# The rest of the image is set to black.\n",
    "def region_of_interest(img, vertices):\n",
    "    # Defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)\n",
    "    ignore_mask_color = 255\n",
    "    # Fill pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    # Return the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def perspective_transform(img, inv=False):\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    width, height = img_size\n",
    "    offset = 200\n",
    "    src = np.float32([\n",
    "        [  588,   446 ],\n",
    "        [  691,   446 ],\n",
    "        [ 1126,   673 ],\n",
    "        [  153 ,   673 ]])\n",
    "    dst = np.float32([[offset, 0], [img_size[0] - offset, 0], [img_size[0] - offset, img_size[1]], [offset, img_size[1]]])\n",
    "    M = cv2.getPerspectiveTransform(src,dst)\n",
    "    Minv = cv2.getPerspectiveTransform(dst, src)\n",
    "    binary_warped = cv2.warpPerspective(img,M, (width, height))\n",
    "    return binary_warped, M, Minv\n",
    "\n",
    "# PERSPECTIVE TRANSFORM\n",
    "def warp(thresholded):\n",
    "    warped_img, M, Minv = perspective_transform(thresholded)\n",
    "    # Define image mask (polygon of interest)\n",
    "    imshape = warped_img.shape\n",
    "    vertices = np.array([[(200, imshape[0]), (200, 0), (imshape[1] - 200, 0), \n",
    "                      (imshape[1]-200, imshape[0])]], dtype=np.int32)\n",
    "    masked_img = region_of_interest(warped_img, vertices)\n",
    "    return masked_img, M, Minv, warped_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image Thresholding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# COLOR / GRADIENT THRESHOLD\n",
    "def dir_threshold(img, sobel_kernel=15, thresh=(0.7, 1.2)):\n",
    "    # Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    # Calculate the x and y gradients\n",
    "    sobelx = cv2.Sobel(gray[:,:,2], cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray[:,:,2], cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Take the absolute value of the gradient direction, \n",
    "    # apply a threshold, and create a binary image result\n",
    "    absgraddir = np.arctan2(np.absolute(sobely), np.absolute(sobelx))\n",
    "    binary_output =  np.zeros_like(absgraddir)\n",
    "    binary_output[(absgraddir >= thresh[0]) & (absgraddir <= thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "# Define a function to return the magnitude of the gradient\n",
    "# for a given sobel kernel size and threshold values\n",
    "def mag_thresh(img, sobel_kernel=9, mag_thresh=(30, 255)):\n",
    "    # Convert to grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    # Take both Sobel x and y gradients\n",
    "    sobelx = cv2.Sobel(gray[:,:,2], cv2.CV_64F, 1, 0, ksize=sobel_kernel)\n",
    "    sobely = cv2.Sobel(gray[:,:,2], cv2.CV_64F, 0, 1, ksize=sobel_kernel)\n",
    "    # Calculate the gradient magnitude\n",
    "    gradmag = np.sqrt(sobelx**2 + sobely**2)\n",
    "    # Rescale to 8 bit\n",
    "    scale_factor = np.max(gradmag)/255 \n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8) \n",
    "    # Create a binary image of ones where threshold is met, zeros otherwise\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= mag_thresh[0]) & (gradmag <= mag_thresh[1])] = 1\n",
    "\n",
    "    # Return the binary image\n",
    "    return binary_output\n",
    "\n",
    "\n",
    "def threshold(img, color=False, mag_dir_thresh=False):\n",
    "    \"\"\"Threshhold image on saturation channel and \n",
    "    using magnitude gradient\"\"\"\n",
    "    img = np.copy(img)\n",
    "    \n",
    "    # Convert to HLS color space and separate the V channel\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS).astype(np.float)\n",
    "    \n",
    "    \n",
    "    ## White Color\n",
    "    lower_white = np.array([0,210,0], dtype=np.uint8)\n",
    "    upper_white = np.array([255,255,255], dtype=np.uint8)\n",
    "    white_mask = cv2.inRange(hls, lower_white, upper_white)\n",
    "    \n",
    "    ## Yellow Color\n",
    "    lower_yellow = np.array([18,0,100], dtype=np.uint8)\n",
    "    upper_yellow = np.array([30,220,255], dtype=np.uint8)\n",
    "    yellow_mask = cv2.inRange(hls, lower_yellow, upper_yellow)  \n",
    "    \n",
    "    combined_binary = np.zeros_like(white_mask)\n",
    "    \n",
    "    # Dir Mag Threshold\n",
    "    if mag_dir_thresh:\n",
    "        dir_mask = dir_threshold(img)\n",
    "        mag_mask = mag_thresh(img)\n",
    "        combined_binary[((dir_mask == 1) & (mag_mask == 1))] = 255\n",
    "        \n",
    "    if color:\n",
    "        return np.dstack((white_mask, yellow_mask, combined_binary))\n",
    "    \n",
    "    else:\n",
    "        combined_binary[((white_mask == 255) | (yellow_mask == 255))] = 255\n",
    "        combined_binary[(combined_binary == 255)] = 1\n",
    "        return combined_binary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect lane pixels and fit to find lane boundary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def find_base_pts(warped):\n",
    "    # Take a histogram of the bottom half of the masked image\n",
    "    histogram = np.sum(warped[warped.shape[0]//2:,:], axis=0)\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    return midpoint, leftx_base, rightx_base\n",
    "\n",
    "# Define conversions in x and y from pixels space to meters\n",
    "ym_per_pix = 30/720 # meters per pixel in y dimension\n",
    "xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "\n",
    "# DETECT LANE LINES\n",
    "def find_lines(image, nwindows=9, margin=110, minpix=50):\n",
    "    \"\"\"\n",
    "    Find the polynomial representation of the lines in the `image` using:\n",
    "    - `nwindows` as the number of windows.\n",
    "    - `margin` as the windows margin.\n",
    "    - `minpix` as minimum number of pixes found to recenter the window.\n",
    "    - `ym_per_pix` meters per pixel on Y.\n",
    "    - `xm_per_pix` meters per pixels on X.\n",
    "    \n",
    "    Returns (left_fit, right_fit, left_lane_inds, right_lane_inds, out_img, nonzerox, nonzeroy)\n",
    "    \"\"\"    \n",
    "    # Make a binary and transform image\n",
    "    binary_warped = image\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(binary_warped[binary_warped.shape[0]//2:,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((binary_warped, binary_warped, binary_warped))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint = np.int(histogram.shape[0]/2)\n",
    "    leftx_base = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "\n",
    "    # Set height of windows\n",
    "    window_height = np.int(binary_warped.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero = binary_warped.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    \n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    \n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds = []\n",
    "    right_lane_inds = []\n",
    "    \n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low = binary_warped.shape[0] - (window+1)*window_height\n",
    "        win_y_high = binary_warped.shape[0] - window*window_height\n",
    "        win_xleft_low = leftx_current - margin\n",
    "        win_xleft_high = leftx_current + margin\n",
    "        win_xright_low = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "    \n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx = nonzerox[left_lane_inds]\n",
    "    lefty = nonzeroy[left_lane_inds]\n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds]\n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    ploty = np.linspace(0, image.shape[0]-1, image.shape[0] )\n",
    "    \n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit_m = np.polyfit(lefty*ym_per_pix, leftx*xm_per_pix, 2)\n",
    "    right_fit_m = np.polyfit(righty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    \n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]] = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    \n",
    "    return (out_img, ploty, leftx, lefty, rightx, righty, left_fit, right_fit, left_fit_m, right_fit_m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Determine curvature of the lane and vehicle position with respect to center.\n",
    "\n",
    "Now let's update the pipeline to include calculations to determine curvature of the lane and vehicle position with respect to center.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calculate_curvature(yRange, left_fit_cr):\n",
    "    \"\"\"\n",
    "    Returns the curvature of the polynomial `fit` on the y range `yRange`.\n",
    "    \"\"\"\n",
    "    \n",
    "    return ((1 + (2*left_fit_cr[0]*yRange*ym_per_pix + left_fit_cr[1])**2)**1.5) / np.absolute(2*left_fit_cr[0])\n",
    "\n",
    "# Calculate vehicle center\n",
    "def calculate_center(img, left_fit_m, right_fit_m):\n",
    "    xMax = img.shape[1]*xm_per_pix\n",
    "    yMax = img.shape[0]*ym_per_pix\n",
    "    vehicleCenter = xMax / 2\n",
    "    lineLeft = left_fit_m[0]*yMax**2 + left_fit_m[1]*yMax + left_fit_m[2]\n",
    "    lineRight = right_fit_m[0]*yMax**2 + right_fit_m[1]*yMax + right_fit_m[2]\n",
    "    lineMiddle = lineLeft + (lineRight - lineLeft)/2\n",
    "    diffFromVehicle = lineMiddle - vehicleCenter\n",
    "    if diffFromVehicle > 0:\n",
    "        message = '{:.2f} m right'.format(diffFromVehicle)\n",
    "    else:\n",
    "        message = '{:.2f} m left'.format(-diffFromVehicle)\n",
    "    return message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lane Mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_line(img, left_fit, right_fit, Minv):\n",
    "    \"\"\"\n",
    "    Draw the lane lines on the image `img` using the poly `left_fit` and `right_fit`.\n",
    "    \"\"\"\n",
    "    yMax = img.shape[0]\n",
    "    ploty = np.linspace(0, yMax - 1, yMax)\n",
    "    color_warp = np.zeros_like(img).astype(np.uint8)\n",
    "    \n",
    "    # Calculate points.\n",
    "    left_fitx = left_fit[0]*ploty**2 + left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    cv2.fillPoly(color_warp, np.int_([pts]), (0,255, 0))\n",
    "    \n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, Minv, (img.shape[1], img.shape[0]))\n",
    "    \n",
    "    lane_image = cv2.addWeighted(img, 1, newwarp, 0.3, 0)\n",
    "    \n",
    "    return lane_image\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "# DRAWING\n",
    "def draw_res(lane_image, undistorted, out_img, ploty, labels, heatmap):\n",
    "    \n",
    "    result = lane_image\n",
    "    \n",
    "    x_offset1 = result.shape[1] - 320 - 30\n",
    "    y_offset = 65\n",
    "    thumb = cv2.resize(out_img, (320, 200), interpolation = cv2.INTER_CUBIC)\n",
    "    result[y_offset:y_offset + thumb.shape[0], x_offset1:x_offset1 + thumb.shape[1]] = thumb\n",
    "    \n",
    "    # Resize the heatmap image\n",
    "    resized_heatmap = 255*cv2.resize(heatmap, (320, 200), interpolation=cv2.INTER_AREA)\n",
    "    # Compose the 3 channel Heatmap\n",
    "    thumb = cv2.merge([resized_heatmap, resized_heatmap, resized_heatmap])\n",
    "    # Add Heatmap to the Image\n",
    "    x_offset2 = result.shape[1] - 320*2 - 30*2\n",
    "    result[y_offset:y_offset + thumb.shape[0], x_offset2:x_offset2 + thumb.shape[1]] = thumb\n",
    "\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    cv2.putText(result, 'Vehicles Heatmap', (x_offset2+20, 50), font, 1, (255,255,255), 2)\n",
    "    cv2.putText(result, 'Lane Lines', (x_offset1+70, 50), font, 1, (255,255,255), 2)\n",
    "    result = draw_labeled_bboxes(np.copy(result), labels)\n",
    "\n",
    "    #plot_row2(undistorted, result, 'Original Frame (Undistorted)', 'Processed Frame')\n",
    "    #fig = plt.figure(figsize=(20, 8))\n",
    "    #plt.imshow(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle Detection Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "\n",
    "# For universal plotting of results\n",
    "def plot_row4(img1, img2, img3, img4, label_1, label_2, label_3, label_4, graysc=True):\n",
    "    # Plot the result (1 row with 4 images)\n",
    "    f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(12, 4))\n",
    "    f.tight_layout()\n",
    "    if graysc:\n",
    "        ax1.imshow(img1, cmap='gray')\n",
    "    else:\n",
    "        ax1.imshow(img1)\n",
    "    ax1.set_title(label_1, fontsize=14)\n",
    "    ax2.imshow(img2, cmap='gray')\n",
    "    ax2.set_title(label_2, fontsize=14)\n",
    "    ax3.imshow(img3, cmap='gray')\n",
    "    ax3.set_title(label_3, fontsize=14)\n",
    "    ax4.imshow(img4, cmap='gray')\n",
    "    ax4.set_title(label_4, fontsize=14)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "    \n",
    "def convert_color(img, conv='RGB2YCrCb'):\n",
    "    if conv == 'RGB2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    if conv == 'BGR2YCrCb':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_BGR2YCrCb)\n",
    "    if conv == 'RGB2LUV':\n",
    "        return cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "\n",
    "# Define a function to return HOG features and visualization\n",
    "def get_hog_features(img, orient, pix_per_cell, cell_per_block, \n",
    "                     vis=False, feature_vec=True):\n",
    "    # Call with two outputs if vis==True\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, \n",
    "                                  pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                  transform_sqrt=False, \n",
    "                                  visualise=vis, feature_vector=feature_vec)\n",
    "        return features, hog_image\n",
    "    # Otherwise call with one output\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, \n",
    "                       pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), \n",
    "                       transform_sqrt=False, \n",
    "                       visualise=vis, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    color1 = cv2.resize(img[:,:,0], size).ravel()\n",
    "    color2 = cv2.resize(img[:,:,1], size).ravel()\n",
    "    color3 = cv2.resize(img[:,:,2], size).ravel()\n",
    "    return np.hstack((color1, color2, color3))\n",
    "\n",
    "# Define a function to compute color histogram features \n",
    "# NEED TO CHANGE bins_range if reading .png files with mpimg!\n",
    "def color_hist(img, nbins=32):    #bins_range=(0, 256)\n",
    "    # Compute the histogram of the color channels separately\n",
    "    channel1_hist = np.histogram(img[:,:,0], bins=nbins)\n",
    "    channel2_hist = np.histogram(img[:,:,1], bins=nbins)\n",
    "    channel3_hist = np.histogram(img[:,:,2], bins=nbins)\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((channel1_hist[0], channel2_hist[0], channel3_hist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "\n",
    "# Define a function to extract features from a single image window\n",
    "# This function is very similar to extract_features()\n",
    "# just for a single image rather than list of images\n",
    "def single_img_features(img, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    #1) Define an empty list to receive features\n",
    "    img_features = []\n",
    "    #2) Apply color conversion if other than 'RGB'\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else: feature_image = np.copy(img)      \n",
    "    #3) Compute spatial features if flag is set\n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        #4) Append features to list\n",
    "        img_features.append(spatial_features)\n",
    "    #5) Compute histogram features if flag is set\n",
    "    if hist_feat == True:\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        #6) Append features to list\n",
    "        img_features.append(hist_features)\n",
    "    #7) Compute HOG features if flag is set\n",
    "    if hog_feat == True:\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_features = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                hog_features.extend(get_hog_features(feature_image[:,:,channel], \n",
    "                                    orient, pix_per_cell, cell_per_block, \n",
    "                                    vis=False, feature_vec=True))      \n",
    "        else:\n",
    "            hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                        pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "        # For plotting\n",
    "        pics = []\n",
    "        for channel in range(feature_image.shape[2]):\n",
    "            feat, pic = get_hog_features(feature_image[:,:,channel], orient, pix_per_cell, \n",
    "                                     cell_per_block, vis=True, feature_vec=True)\n",
    "            pics.append(pic)\n",
    "        plot_row4(feature_image, pics[0], pics[1], pics[2], 'YCrCb Image', 'HOG channel 0', \n",
    "                  'HOG channel 1', 'HOG channel 2', graysc=True)\n",
    "        #8) Append features to list\n",
    "        img_features.append(hog_features)\n",
    "    #9) Return concatenated array of features\n",
    "    return np.concatenate(img_features)\n",
    "\n",
    "\n",
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features(imgs, color_space='RGB', spatial_size=(32, 32),\n",
    "                     hist_bins=32, orient=9, \n",
    "                     pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                     spatial_feat=True, hist_feat=True, hog_feat=True):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        file_features = []\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if color_space != 'RGB':\n",
    "            if color_space == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif color_space == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif color_space == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif color_space == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "            elif color_space == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)\n",
    "        else: feature_image = np.copy(image)      \n",
    "\n",
    "        if spatial_feat == True:\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            file_features.append(spatial_features)\n",
    "        if hist_feat == True:\n",
    "            # Apply color_hist()\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "            file_features.append(hist_features)\n",
    "        if hog_feat == True:\n",
    "        # Call get_hog_features() with vis=False, feature_vec=True\n",
    "            if hog_channel == 'ALL':\n",
    "                hog_features = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_features.append(get_hog_features(feature_image[:,:,channel], \n",
    "                                        orient, pix_per_cell, cell_per_block, \n",
    "                                        vis=False, feature_vec=True))\n",
    "                hog_features = np.ravel(hog_features)        \n",
    "            else:\n",
    "                hog_features = get_hog_features(feature_image[:,:,hog_channel], orient, \n",
    "                            pix_per_cell, cell_per_block, vis=True, feature_vec=True)\n",
    "            # Append the new feature vector to the features list\n",
    "            file_features.append(hog_features)\n",
    "            \n",
    "        features.append(np.concatenate(file_features))\n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import pickle\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from skimage.feature import hog\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.ndimage.measurements import label\n",
    "%matplotlib inline\n",
    "\n",
    "# CLASSIFIER's PARAMETERS\n",
    "print('Loading dataset...')\n",
    "# Read in cars and notcars\n",
    "cars = glob.glob('dataset/vehicles/**/*.png', recursive=True)\n",
    "notcars = glob.glob('dataset/non-vehicles/**/*.png', recursive=True)\n",
    "# Stat\n",
    "print('CARS: {}'.format(len(cars)))\n",
    "print('NOTCARS: {}'.format(len(notcars)))\n",
    "# Tweak these parameters\n",
    "color_space    = 'YCrCb'    # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient         = 9          # HOG orientations\n",
    "pix_per_cell   = 8          # HOG pixels per cell\n",
    "cell_per_block = 2          # HOG cells per block\n",
    "hog_channel    = 'ALL'      # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size   = (32, 32)   # Spatial binning dimensions\n",
    "hist_bins      = 32         # Number of histogram bins\n",
    "spatial_feat   = True       # Spatial features on or off\n",
    "hist_feat      = True       # Histogram features on or off\n",
    "hog_feat       = True       # HOG features on or off\n",
    "\n",
    "car = mpimg.imread(cars[10])\n",
    "notcar = mpimg.imread(notcars[10])\n",
    "#plot_row2(car, notcar, 'Car', 'Not Car')\n",
    "car_features = single_img_features(car, color_space=color_space,\n",
    "                                   spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                                   orient=orient, pix_per_cell=pix_per_cell, \n",
    "                                   cell_per_block=cell_per_block, \n",
    "                                   hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                                   hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "print('car_features: DONE')\n",
    "notcar_features = single_img_features(notcar, color_space=color_space,\n",
    "                                      spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                                      orient=orient, pix_per_cell=pix_per_cell, \n",
    "                                      cell_per_block=cell_per_block, \n",
    "                                      hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                                      hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "print('notcar_features: DONE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLASSIFIER TRAINING PIPELINE\n",
    "car_features = extract_features(cars, color_space=color_space, \n",
    "                                spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                                orient=orient, pix_per_cell=pix_per_cell, \n",
    "                                cell_per_block=cell_per_block, \n",
    "                                hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                                hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "print('car_features: DONE')\n",
    "notcar_features = extract_features(notcars, color_space=color_space, \n",
    "                                   spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                                   orient=orient, pix_per_cell=pix_per_cell, \n",
    "                                   cell_per_block=cell_per_block, \n",
    "                                   hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                                   hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "print('notcar_features: DONE')\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.2, random_state=rand_state)\n",
    "\n",
    "print('Using:', orient, 'orientations', pix_per_cell, \n",
    "      'pixels per cell and', cell_per_block, 'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC()\n",
    "# Check the training time for the SVC\n",
    "t = time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2 - t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "\n",
    "# Save data to pickle file\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"svc\"] = svc\n",
    "dist_pickle[\"scaler\"] = X_scaler\n",
    "dist_pickle[\"orient\"] = orient\n",
    "dist_pickle[\"pix_per_cell\"] = pix_per_cell\n",
    "dist_pickle[\"cell_per_block\"] = cell_per_block\n",
    "dist_pickle[\"spatial_size\"] = spatial_size\n",
    "dist_pickle[\"hist_bins\"] = hist_bins\n",
    "pickle.dump(dist_pickle, open(\"svc_pickle.p\", 'wb') )\n",
    "\n",
    "print('Classifier parameters were saved to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Classifier Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Loading Classifier parameters...')\n",
    "dist_pickle = pickle.load( open(\"svc_pickle.p\", \"rb\" ) )\n",
    "svc = dist_pickle[\"svc\"]\n",
    "X_scaler = dist_pickle[\"scaler\"]\n",
    "orient = dist_pickle[\"orient\"]\n",
    "pix_per_cell = dist_pickle[\"pix_per_cell\"]\n",
    "cell_per_block = dist_pickle[\"cell_per_block\"]\n",
    "spatial_size = dist_pickle[\"spatial_size\"]\n",
    "hist_bins = dist_pickle[\"hist_bins\"]\n",
    "\n",
    "print('Loading is done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a single function that can extract features using hog sub-sampling and make predictions\n",
    "def find_cars(img, svc, X_scaler, orient, pix_per_cell, cell_per_block, \n",
    "              spatial_size, hist_bins):\n",
    "    draw_img = np.copy(img)\n",
    "    img = img.astype(np.float32)/255\n",
    "    \n",
    "    ystart_ystop_scale = [(380, 480, 1), (400, 600, 1.5), (500, 700, 2.5)]\n",
    "    win_pos = []\n",
    "    # ADD MULTISCALING:\n",
    "    for (ystart, ystop, scale) in ystart_ystop_scale:\n",
    "        img_tosearch = img[ystart:ystop, :, :]\n",
    "        ctrans_tosearch = convert_color(img_tosearch, conv='RGB2YCrCb')\n",
    "        \n",
    "        if scale != 1:\n",
    "            imshape = ctrans_tosearch.shape\n",
    "            ctrans_tosearch = cv2.resize(ctrans_tosearch, (np.int(imshape[1]/scale), np.int(imshape[0]/scale)))\n",
    "        \n",
    "        ch1 = ctrans_tosearch[:,:,0]\n",
    "        ch2 = ctrans_tosearch[:,:,1]\n",
    "        ch3 = ctrans_tosearch[:,:,2]\n",
    "\n",
    "        # Define blocks and steps as above\n",
    "        nxblocks = ((ch1.shape[1] // pix_per_cell) - cell_per_block + 1)\n",
    "        nyblocks = ((ch1.shape[0] // pix_per_cell) - cell_per_block + 1)\n",
    "        nfeat_per_block = orient * cell_per_block**2\n",
    "    \n",
    "        # 64 was the orginal sampling rate, with 8 cells and 8 pix per cell\n",
    "        window = 8*8\n",
    "        nblocks_per_window = (window // pix_per_cell) - cell_per_block + 1\n",
    "        cells_per_step = 2  # Instead of overlap, define how many cells to step\n",
    "        nxsteps = (nxblocks - nblocks_per_window) // cells_per_step\n",
    "        nysteps = (nyblocks - nblocks_per_window) // cells_per_step\n",
    "    \n",
    "        # Compute individual channel HOG features for the entire image\n",
    "        hog1 = get_hog_features(ch1, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        hog2 = get_hog_features(ch2, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "        hog3 = get_hog_features(ch3, orient, pix_per_cell, cell_per_block, feature_vec=False)\n",
    "    \n",
    "\n",
    "        for xb in range(nxsteps + 1):\n",
    "            for yb in range(nysteps + 1):\n",
    "                ypos = yb * cells_per_step\n",
    "                xpos = xb * cells_per_step\n",
    "                # Extract HOG for this patch\n",
    "                hog_feat1 = hog1[ypos:ypos+nblocks_per_window, xpos:xpos + nblocks_per_window].ravel() \n",
    "                hog_feat2 = hog2[ypos:ypos+nblocks_per_window, xpos:xpos + nblocks_per_window].ravel() \n",
    "                hog_feat3 = hog3[ypos:ypos+nblocks_per_window, xpos:xpos + nblocks_per_window].ravel() \n",
    "                hog_features = np.hstack((hog_feat1, hog_feat2, hog_feat3))\n",
    "\n",
    "                xleft = xpos * pix_per_cell\n",
    "                ytop = ypos * pix_per_cell\n",
    "\n",
    "                # Extract the image patch\n",
    "                subimg = cv2.resize(ctrans_tosearch[ytop:ytop + window, xleft:xleft + window], (64, 64))\n",
    "          \n",
    "                # Get color features\n",
    "                spatial_features = bin_spatial(subimg, size=spatial_size)\n",
    "                hist_features = color_hist(subimg, nbins=hist_bins)\n",
    "\n",
    "                # Scale features and make a prediction\n",
    "                test_features = X_scaler.transform(np.hstack((spatial_features, hist_features, hog_features)).reshape(1, -1))    \n",
    "                test_prediction = svc.predict(test_features)\n",
    "            \n",
    "                # If detected\n",
    "                if test_prediction == 1:\n",
    "                    xbox_left = np.int(xleft * scale)\n",
    "                    ytop_draw = np.int(ytop * scale)\n",
    "                    win_draw = np.int(window * scale)\n",
    "                    cv2.rectangle(draw_img, (xbox_left, ytop_draw + ystart), \n",
    "                                  (xbox_left + win_draw, ytop_draw + win_draw + ystart), (0,0,255), 2)\n",
    "                    win_pos.append(((xbox_left, ytop_draw + ystart), \n",
    "                                    (xbox_left + win_draw, ytop_draw + win_draw + ystart)))\n",
    "    return draw_img, win_pos\n",
    "\n",
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "    # Return updated heatmap\n",
    "    return heatmap\n",
    "\n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Accumulation of labels from last N frames\n",
    "class LabelsQueue():\n",
    "    def __init__ (self):\n",
    "        # Number labels to store\n",
    "        self.queue_len = 10 \n",
    "        self.queue = []\n",
    "\n",
    "    # Put new frame\n",
    "    def put_labels(self, labels):\n",
    "        if (len(self.queue) > self.queue_len):\n",
    "            tmp = self.queue.pop(0)\n",
    "        self.queue.append(labels)\n",
    "    \n",
    "    # Get last N frames hot boxes\n",
    "    def get_labels(self):\n",
    "        b = []\n",
    "        for label in self.queue:\n",
    "            b.extend(label)\n",
    "        return b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vehicle Detection Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def detection_pipeline(img):\n",
    "    out_img, win_pos = find_cars(img, svc, X_scaler, orient, pix_per_cell, \n",
    "                                 cell_per_block, spatial_size, hist_bins)\n",
    "    # Read in image similar to one shown above \n",
    "    heat = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "    \n",
    "    # AVG boxes\n",
    "    last_hot_labels.put_labels(win_pos)\n",
    "    win_pos = last_hot_labels.get_labels()\n",
    "    \n",
    "    # Add heat to each box in box list\n",
    "    heat = add_heat(heat, win_pos)\n",
    "    # Apply threshold to help remove false positives\n",
    "    heat = apply_threshold(heat, 22)\n",
    "    # Visualize the heatmap when displaying\n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels = label(heatmap)\n",
    "    draw_img = draw_labeled_bboxes(np.copy(img), labels)\n",
    "    \n",
    "    #plot_row2(img, out_img, 'Source', 'All Detections')\n",
    "    #plot_row2(draw_img, heatmap, 'Car Positions', 'Heat Map')\n",
    "    return labels, heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yRange = 719\n",
    "\n",
    "def image_pipeline(image, fontScale=0.7):\n",
    "    undistorted = undistort(image)\n",
    "    # Threshold image\n",
    "    thresholded = threshold(image)\n",
    "    # Warp image\n",
    "    warped, M, Minv, warped_full = warp(thresholded)\n",
    "    # Detect lane lines\n",
    "    out_img, ploty, leftx, lefty, rightx, righty, left_fit, right_fit, left_fit_m, right_fit_m = find_lines(warped_full)\n",
    "    \n",
    "    lane_image = draw_line(image, left_fit, right_fit, Minv)\n",
    "    \n",
    "    # Calculate curvature\n",
    "    left_curvature = calculate_curvature(yRange, left_fit_m)\n",
    "    right_curvature = calculate_curvature(yRange, right_fit_m)\n",
    "    \n",
    "    # Calculate vehicle center\n",
    "    message = calculate_center(image, left_fit_m, right_fit_m)\n",
    "    \n",
    "    # Draw info\n",
    "    font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    fontColor = (255, 255, 255)\n",
    "    cv2.putText(lane_image, 'Left curvature: {:.0f} m'.format(left_curvature), (20, 50), font, fontScale, fontColor, 2)\n",
    "    cv2.putText(lane_image, 'Right curvature: {:.0f} m'.format(right_curvature), (20, 120), font, fontScale, fontColor, 2)\n",
    "    cv2.putText(lane_image, 'Vehicle is {} of center'.format(message), (20, 190), font, fontScale, fontColor, 2)\n",
    "    \n",
    "    # Vehicle detection pipeline\n",
    "    labels, heatmap = detection_pipeline(undistorted)\n",
    "    # Draw output\n",
    "    proc_img = draw_res(lane_image, undistorted, out_img, ploty, labels, heatmap)\n",
    "    #plot_row2(undistorted, proc_img, 'Undistorted', 'Result')\n",
    "    return proc_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final pipeline test on Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load original image from camera\n",
    "last_hot_labels = LabelsQueue()\n",
    "image = mpimg.imread('test_images/test1.jpg')\n",
    "proc_img = image_pipeline(image)\n",
    "\n",
    "plt.figure(figsize=(10,20))\n",
    "plt.imshow(proc_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Video processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "last_hot_labels = LabelsQueue()\n",
    "video_output = 'test3.mp4'\n",
    "clip = VideoFileClip('test_video3.mp4')\n",
    "\n",
    "output_clip = clip.fl_image(image_pipeline)\n",
    "%time output_clip.write_videofile(video_output, audio=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HTML(\"\"\"\n",
    "<video width=\"960\" height=\"540\" controls>\n",
    "  <source src=\"{0}\">\n",
    "</video>\n",
    "\"\"\".format(output_video))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
